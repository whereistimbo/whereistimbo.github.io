<!DOCTYPE html>
<html>
 <head>
  <title>whereistimbo's random mumblings</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="style.css">
 </head>
 <body>
  <header>
   <h1>whereistimbo's random mumblings</h1>
   <a href="https://facebook.com/whereistimbo">facebook.com/whereistimbo</a> <br><a href="https://twitter.com/whereistimbo">twitter.com/whereistimbo</a><br> <a href="https://instagram.com/whereistimbo">instagram.com/whereistimbo</a> <br><a href="https://m.me/whereistimbo">m.me/whereistimbo</a><br>
<a href="https://github.com/whereistimbo">github.com/whereistimbo</a><br><a href="https://gitlab.com/whereistimbo">gitlab.com/whereistimbo</a><br><a href="mailto:whereistimbo@outlook.co.il">whereistimbo@outlook.co.il</a>
  </header>
  <!--
<div id="121">
<h2 class="date">2021-03-25</h2>
<p class="day">Hari Ke-121</p>
<p class="hour"></p>
<p class="rev"></p>
<blockquote>
<p></p>
</blockquote>
</div>
-->
  <main>
   <!--Entry 1-->
   <h2>2020-05-09 17:40:56</h2>
   <p>Tags: Computer; Programming; Shell</p>

<p>Today I'm toying with PowerShell. IMO Better than bash as PowerShell deals with object, so I don't spend more effort using AWK, grep, sed, and so on.</p>

<p>Use case #1: To build a TFRecord of a dataset, I need to create .pbtxt, which is a collection of label in JSON like data structure</p>
<p>Example entry of .pbtxt:</p>

<code>item {
  id: 1
  name: 'aeroplane'
}</code>



<p>In case of Fruit360, the labels are the directory/folder name, so using PowerShell, I can get list of directories using 'ls'.
The command 'ls' itself produce objects which contain several properties and method, to inspect the object produced by 'ls', I use command:</p>

<code>ls | Get-Member</code>
<p>Then I found that object produced by 'ls'  produce several properties like FullName, Name, Parent, Root, LastAccessTime, etc.
Since I only need the name of the folder, so I only need Name property.</p>

<code>ls | Select-Object -Property Name</code>
<p>Then I store the result of the command into variable:</p>

<code>$nameList = $(ls | Select-Object -Property Name)</code>
<p>Then using for loop is enough to produce the pbtxt file:</p>

<pre><code>$(for ($i=0; $i -lt $nameList.Length; $i++){ "item {`
   id: $($i+1)`
   name: '$($nameList.Name[$i])'`
 }"} ) | Out-File -FilePath .\fruit360_label_map.pbtxt</code></pre>
<p>Use case #2: TFRecord data structure does not have hierarchy, and file name is one of the required field, so I have to change the file name in the dataset to not having duplicate file name. In my case, Fruit360 dataset consists of folders as label and each folder consists of images that might have identical file name in another folder. To solve this issue I prepend the label/folder name of the image in the file name.</p>

<pre><code>$listdir = ls
foreach ($i in $listdir) {$listfile = $(ls ".\$($i.Name)")
$newfoldername = $($i.Name -replace " ","_")
$newfoldername
foreach ($j in $listfile) {Rename-Item -Path $j.FullName -NewName "$newfoldername`_$($j.Name)"}}</code></pre>
<p>Tips for using PowerShell from <a href="https://news.ycombinator.com/item?id=22966238">https://news.ycombinator.com/item?id=22966238</a></p>

<blockquote>
<p>Fr0styMatt88 wrote:</p>
<p>I've mentioned this in other Powershell HN threads but you might want to try these two commands to make discoverability much better IMHO:</p>
<code>Set-PSReadLineKeyHandler -Key Tab -Function MenuComplete

Set-PSReadLineOption -ShowToolTips</code>

<p>Also note that you can get in-console help on most commands without having to go out to a web browser. On the ones I've tried, examples are also included which help output too.</p>

<p>Help will also list available commands; eg:</p>

<code>help json</code>

<p>Shows me the three commands available from my shell: ConvertFrom-Json, ConvertTo-Json and Test-Json.</p>

<p>There is also Get-Command, which you can filter for command discovery, ie:</p>

<code>Get-Command | where Name -Like "Json"</code>

<p>The advantage to PowerShell being object-based here is that if you press <TAB> after typing where, the list of completions you get will include the properties that are in the object returned as the result of Get-Command.</p>

<p>I also use Cmder for a much nicer console than cmd.exe. I haven't tried the latest version of the new Windows Terminal but I hear it's also nice.</p>
</blockquote>
   <!--Entry 2-->
   <h2>2020-05-10 10:06:46</h2>
   <p>Tags: Computer; Windows</p>
   <p>I had Python failed to install TensorFlow package today, as I search on Google, turns out the problem is the File Path which is too long. Here's the error message:</p>

<pre><code>ERROR: Could not install packages due to an EnvironmentError: [Errno 2] No such file or directory: 
'C:\\Users\\whereistimbo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorboard_plugin_wit\\_vendor\\tensorflow_serving\\sources\\storage_path\\__pycache__\\file_system_storage_path_source_pb2.cpython-38.pyc'</code></pre>
<p>To fix it, open regedit, go to Computer\HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\FileSystem , and modify LongPathsEnabled to 1</p>

<p>I found the solution from: <a href="https://blog.csdn.net/qq_33204646/article/details/102606383">https://blog.csdn.net/qq_33204646/article/details/102606383</a></p>
   <!--Entry 3-->
   <h2>2020-05-10 16:26:47</h2>
   <p>Tags: Computer; Windows; MSPaint</p>

<p>I downloaded The MSPaint that found in Windows 95/98/Me/XP, as it has powerful feature that the recent MSPaint lack, namely 'skew'.</p>
   <!--Entry 4-->
   <h2>2020-05-11 13:27:05</h2>
   <p>Tags: Computer; Neural Network; TensorFlow; Google Colab</p>

<p>When using Google Colab, DO NOT USE FILES DIRECTLY FROM GOOGLE DRIVE! Seriously!</p>

<p>Files you want to use from Google Drive should be zipped before being copied to Google Colab runtime.
Using files directly from Google Drive is very slow as heck!
Copying a lot of non zipped files form Google Drive is still slow as heck!</p>

<p>Remember that execution of Google Colab runtime is capped to 12 hours!</p>

<p>(On side note to remedy this situation I tried to spin up another Colab runtime in another Chrome window while my initial Colab Runtime is still active and GUESS WHAT, the moment I'm using it when the runtime is ready I was instantly disconnected from the runtime and suddenly the Colab Notebook is busy meaning I am not able to connect to any other runtime! Now I'm trying to use Kaggle for my 2nd runtime)</p>

<p>~<p>

<p>(Another note: I found out that Google Drive mount on Kaggle isn't supported, but I found that I can spin up another runtime in Google Colab without any other problem. Dunno what happened earlier. If you want a greater success of summoning another runtime, try to summon runtime without any optimization (TPU or GPU))</p>
   <!--Entry 5-->
   <h2>2020-05-11 14:23:06</h2>
   <p>Tags: Computer; Linux; Google Colab</p>

<p>Copying with cp seems very tedious, in addition, you can't resume when you are being interrupted mid-progress. Google Colab itself saved all files on the /content directory even if you close and reopen notebook (CMIIW), so it's best using rsync so that you can also resume the copy progress</p>

<p>Example</p>

<pre><code>!rsync -a --info=progress2 /content/drive/My\ Drive/datasets/Fruit-Images-Dataset-master /content/</pre></code>
<p>(side note: the rsync show ~4.68kB/s (I think dial-up connection is still faster) when copying from Google Drive to Google Colab runtime, perhaps I should redo all rather than tediously waiting for copying)</p>
   <!--Entry 6-->
   <h2>2020-05-11 21:58:46</h2>
   <p>Tags: Computer; Linux</p>

<p>I tried zipping the fruit 360 dataset on Google Colab, when the zipping was done, I compared the list of files of zip of original dataset vs zip of modified dataset. To my surprise, not only the zip of modified dataset larger, it's also missing a lot of files. Never again with zip.</p>

<p>Instead now I just package the dataset with reproducible .tar as said in https://reproducible-builds.org/docs/archives/ :</p>

<pre><code>tar --sort=name \
      --mtime="1970-01-01" \
      --owner=0 --group=0 --numeric-owner \
      --pax-option=exthdr.name=%d/PaxHeaders/%f,delete=atime,delete=ctime \
      -cf product.tar build</code></pre>
<p>(I modify the code to use fixed date instead of using system epoch)
Also I don't use Google Colab again for this kind of thing as (I feel) it's totally unreliable, I'm not sure why.</p>
   <!--Entry 7-->
   <h2>2020-05-11 22:09:39</h2>
   <p>Tags: Computer; TensorFlow</p>

<p>FINALLY After hours of trying I could create the TFRecord (albeit for training only, I could make for test with just few changes)</p>
<p>One thing I was totally confused is how outputting the list of directory under linux (I use Google Compute Preemptible VM) result in directory name listed in random order. Also when I listed all the directory name on Google Colab, I noticed that both Python and Powershell handles alphabetical order differently if there is space after the name (e.g. 'Onion'  and 'Onion Peel') in case of Python (in Google Colab), 'Onion Peel' will be put first before 'Onion', or perhaps it's just system difference as when I tried to list directory in Python under Windows, it appears in alphabetical order. Nevermind it's so confusing that I just sort the list of directory name using Python built in function anyway. I also recreated .pbtxt under Python by combining the script with the TFRecord creation.</p>

<p>Here's the script I use with modification from TensorFlow github, licensed under Apache License 2.0:</p>
<pre><code>
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
import os
from PIL import Image
import hashlib

def int64_feature(value):
  return tf.compat.v1.train.Feature(int64_list=tf.compat.v1.train.Int64List(value=[value]))


def int64_list_feature(value):
  return tf.compat.v1.train.Feature(int64_list=tf.compat.v1.train.Int64List(value=value))


def bytes_feature(value):
  return tf.compat.v1.train.Feature(bytes_list=tf.compat.v1.train.BytesList(value=[value]))


def bytes_list_feature(value):
  return tf.compat.v1.train.Feature(bytes_list=tf.compat.v1.train.BytesList(value=value))


def float_list_feature(value):
  return tf.compat.v1.train.Feature(float_list=tf.compat.v1.train.FloatList(value=value))


def read_examples_list(path):
  """Read list of training or validation examples.
  The file is assumed to contain a single example per line where the first
  token in the line is an identifier that allows us to find the image and
  annotation xml for that example.
  For example, the line:
  xyz 3
  would allow us to find files xyz.jpg and xyz.xml (the 3 would be ignored).
  Args:
    path: absolute path to examples list file.
  Returns:
    list of example identifiers (strings).
  """
  with tf.compat.v1.gfile.GFile(path) as fid:
    lines = fid.readlines()
  return [line.strip().split(' ')[0] for line in lines]


def recursive_parse_xml_to_dict(xml):
  """Recursively parses XML contents to python dict.
  We assume that `object` tags are the only ones that can appear
  multiple times at the same level of a tree.
  Args:
    xml: xml tree obtained by parsing XML file contents using lxml.etree
  Returns:
    Python dictionary holding XML contents.
  """
  if not xml:
    return {xml.tag: xml.text}
  result = {}
  for child in xml:
    child_result = recursive_parse_xml_to_dict(child)
    if child.tag != 'object':
      result[child.tag] = child_result[child.tag]
    else:
      if child.tag not in result:
        result[child.tag] = []
      result[child.tag].append(child_result[child.tag])
  return {xml.tag: result}


def create_tf_example(file, label, id, filepath):
  # TODO(user): Populate the following variables from your example.
  
  fullfilepath = os.path.join(filepath, file)
  with tf.compat.v1.gfile.GFile(fullfilepath, 'rb') as fid:
    encoded_jpg = fid.read()
  key = hashlib.sha256(encoded_jpg).hexdigest()
  filename = file # Filename of the image. Empty if image is not from file
  encoded_image_data = encoded_jpg
  image_format = b'jpeg' # b'jpeg' or b'png'
  im = Image.open(fullfilepath)
  width, height = im.size

  xmins = [0] # List of normalized left x coordinates in bounding box (1 per box)
  xmaxs = [width] # List of normalized right x coordinates in bounding box
             # (1 per box)
  ymins = [0] # List of normalized top y coordinates in bounding box (1 per box)
  ymaxs = [height] # List of normalized bottom y coordinates in bounding box
             # (1 per box)
  classes_text = [label.encode('utf8')] # List of string class name of bounding box (1 per box)
  classes = [id] # List of integer class id of bounding box (1 per box)

  tf_example = tf.compat.v1.train.Example(features=tf.compat.v1.train.Features(feature={
      'image/height': int64_feature(height),
      'image/width': int64_feature(width),
      'image/filename': bytes_feature(filename.encode('utf8')),
      'image/source_id': bytes_feature(filename.encode('utf8')),
      'image/encoded': bytes_feature(encoded_image_data),
      'image/key/sha256':bytes_feature(key.encode('utf8')),
      'image/format': bytes_feature(image_format),
      'image/object/bbox/xmin': float_list_feature(xmins),
      'image/object/bbox/xmax': float_list_feature(xmaxs),
      'image/object/bbox/ymin': float_list_feature(ymins),
      'image/object/bbox/ymax': float_list_feature(ymaxs),
      'image/object/class/text': bytes_list_feature(classes_text),
      'image/object/class/label': int64_list_feature(classes),
  }))
  return tf_example

writer = tf.compat.v1.python_io.TFRecordWriter('/home/timbo_hidayat_tik15/Downloads/fruit360training.record')

# TODO(user): Write code to read in your dataset to examples variable
with open("/home/timbo_hidayat_tik15/Downloads/fruit360_label_map.pbtxt",mode="w+",encoding="utf-8") as filetowrite:
 pathoflabels = '/home/timbo_hidayat_tik15/Downloads/Fruit-Images-Dataset-modified/Training/'
 listlabels = os.listdir(pathoflabels)
 listlabels = sorted(listlabels, key=str.lower)
 print('Starting')
 for id in range(1, len(listlabels)):
  label = listlabels[id]
  filetowrite.write("item {{\n  id: {0}\n  name: '{1}'\n}}\n".format(id, label))
  pathoffiles = pathoflabels + label
  listfiles = os.listdir(pathoffiles)
  listfiles = sorted(listfiles, key=str.lower)
  print(id)
  print(label)
  for file in listfiles:
    #print(file)
    #fullfilepath = os.path.join(pathoffiles, file)
    tf_example = create_tf_example(file, label, id, pathoffiles)
    writer.write(tf_example.SerializeToString())
filetowrite.close()
writer.close()
</code></pre>
<p>Note 1: I forgot to add the modification I made including removing tf.app.run() because it serves no purpose and removing FLAGS because it caused DuplicateFlagError and UnrecognizedFlagError and as I spent hours searched on Google to solve the issue suddenly I've gotten common sense as I read the code again and found that the only purpose of the FLAGS is just setting up path in python_io.TFRecordWriter which is stupid since adding string of the path is totally adequate. Also added compat.v1 so the code works on TensorFlow v2.</p>
   <!--Entry 8-->
   <h2>2020-05-12 12:25:10</h2>
   <p>Tags: Computer; TensorFlow</p>

<p>Inspecting another TFRecord is as easy as these code:</p>

<pre><code>import tensorflow as tf

filenames_train = '' # Your filename here
raw_dataset_train = tf.data.TFRecordDataset(filenames_train)
for raw_record in raw_dataset_train.take(1):
  example = tf.train.Example()
  example.ParseFromString(raw_record.numpy())
  print(example)</code></pre>
<a href="https://colab.research.google.com/gist/whereistimbo/571d5064c067fece302514c4f570440a/inspect_tfrecord_oxford_pet_dataset.ipynb#scrollTo=Qg0GzjSBdHpJ">Run example in Google Colab</a>
   <!--Entry 9-->
   <h2>2020-05-13 20:33:34</h2>
   <p>Tags: Computer; Linux; Windows</p>


<p>Today I break my Windows installation by moving the partition with GParted. My Windows partition size is 40GB but it's almost full with 1GB free space, and behind it was Debian buster partition whose size is 50GB. So I deleted my Debian partition, moved my Windows partition further and extended my Windows 10 partition. Now it no longer boots. Damn it.</p>

<p>Update 1: Wow after I deleted the partition and point the Windows 10 installer to install in unpartitioned space it finally worked. Ok lesson learned today.</p>
   <!--Entry x-->
   <h2>2021-06-18 23:12:21</h2>
   <p>Tags: </p>


<p>I have deleted and republished the repo in order to delete git history of my old diary, since most of the content is irrelevant anyway. But I've decided to keep some of the entry and will repost them here. </p>

  </main>
 </body>
</html>